{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.models import places_ontop_model\n",
    "from src import custom_losses, custom_metrics, optimizers\n",
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_classes = 6\n",
    "epochs = 64\n",
    "img_size = 224\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: this version uses all kerner regularizers in the places-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = places_ontop_model.PlacesOntop_Model(batch_size, n_classes, epochs, img_size, n_channels, version=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = data.PATH()\n",
    "dataset_path = f'{paths.PROCESSED_DATA_PATH}/'\n",
    "dataset = 'vision_based_dataset'\n",
    "test_dataset_path = f'{dataset_path}/{dataset}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114361 images belonging to 6 classes.\n",
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=True, validation=True, test=True, class_mode_validation='categorical', class_mode_test='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_class_weights(train_generator.classes, model)\n",
    "model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# model.model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# instance_model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### PlacesOntop_Model #####\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 14,847,558\n",
      "Trainable params: 7,212,294\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.show_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 16:48:59.528641 140514997155648 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "W0109 16:48:59.529761 140514997155648 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:354: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0109 16:48:59.532445 140514997155648 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:355: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W0109 16:48:59.534687 140514997155648 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:356: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "**** Class weights ****\n",
      "[2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "*** ** *** *** *** ** ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 16:48:59.865864 140514997155648 deprecation.py:323] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0109 16:49:00.728020 140514997155648 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "894/894 [==============================] - 770s 862ms/step - loss: 2.1090 - categorical_accuracy: 0.2762 - val_loss: 1.8659 - val_categorical_accuracy: 0.3597\n",
      "Epoch 2/64\n",
      "894/894 [==============================] - 835s 934ms/step - loss: 1.9131 - categorical_accuracy: 0.3799 - val_loss: 1.8986 - val_categorical_accuracy: 0.4098\n",
      "Epoch 3/64\n",
      "894/894 [==============================] - 823s 921ms/step - loss: 1.8477 - categorical_accuracy: 0.4145 - val_loss: 1.8582 - val_categorical_accuracy: 0.4365\n",
      "Epoch 4/64\n",
      "894/894 [==============================] - 842s 942ms/step - loss: 1.8124 - categorical_accuracy: 0.4349 - val_loss: 1.7668 - val_categorical_accuracy: 0.4479\n",
      "Epoch 5/64\n",
      "894/894 [==============================] - 838s 938ms/step - loss: 1.7894 - categorical_accuracy: 0.4497 - val_loss: 1.7048 - val_categorical_accuracy: 0.4674\n",
      "Epoch 6/64\n",
      "894/894 [==============================] - 831s 929ms/step - loss: 1.7718 - categorical_accuracy: 0.4622 - val_loss: 1.7845 - val_categorical_accuracy: 0.4799\n",
      "Epoch 7/64\n",
      "894/894 [==============================] - 844s 944ms/step - loss: 1.7581 - categorical_accuracy: 0.4723 - val_loss: 1.7941 - val_categorical_accuracy: 0.4633\n",
      "Epoch 8/64\n",
      "894/894 [==============================] - 832s 930ms/step - loss: 1.7501 - categorical_accuracy: 0.4772 - val_loss: 1.8147 - val_categorical_accuracy: 0.4822\n",
      "Epoch 9/64\n",
      "894/894 [==============================] - 805s 901ms/step - loss: 1.7310 - categorical_accuracy: 0.4893 - val_loss: 1.6978 - val_categorical_accuracy: 0.4950\n",
      "Epoch 10/64\n",
      "894/894 [==============================] - 787s 880ms/step - loss: 1.7255 - categorical_accuracy: 0.4933 - val_loss: 1.6480 - val_categorical_accuracy: 0.5026\n",
      "Epoch 11/64\n",
      "894/894 [==============================] - 784s 877ms/step - loss: 1.7103 - categorical_accuracy: 0.5047 - val_loss: 1.8223 - val_categorical_accuracy: 0.5228\n",
      "Epoch 12/64\n",
      "894/894 [==============================] - 823s 920ms/step - loss: 1.6944 - categorical_accuracy: 0.5149 - val_loss: 1.9218 - val_categorical_accuracy: 0.5067\n",
      "Epoch 13/64\n",
      "894/894 [==============================] - 820s 918ms/step - loss: 1.6848 - categorical_accuracy: 0.5196 - val_loss: 1.9152 - val_categorical_accuracy: 0.5202\n",
      "Epoch 14/64\n",
      "894/894 [==============================] - 820s 917ms/step - loss: 1.6754 - categorical_accuracy: 0.5273 - val_loss: 1.8163 - val_categorical_accuracy: 0.5215\n",
      "Epoch 15/64\n",
      "894/894 [==============================] - 823s 920ms/step - loss: 1.6604 - categorical_accuracy: 0.5351 - val_loss: 1.8271 - val_categorical_accuracy: 0.5386\n",
      "Epoch 16/64\n",
      "894/894 [==============================] - 821s 918ms/step - loss: 1.6572 - categorical_accuracy: 0.5363 - val_loss: 1.6126 - val_categorical_accuracy: 0.5478\n",
      "Epoch 17/64\n",
      "894/894 [==============================] - 823s 921ms/step - loss: 1.6521 - categorical_accuracy: 0.5385 - val_loss: 1.7261 - val_categorical_accuracy: 0.5515\n",
      "Epoch 18/64\n",
      "894/894 [==============================] - 818s 915ms/step - loss: 1.6456 - categorical_accuracy: 0.5447 - val_loss: 1.8181 - val_categorical_accuracy: 0.5304\n",
      "Epoch 19/64\n",
      "894/894 [==============================] - 817s 914ms/step - loss: 1.6395 - categorical_accuracy: 0.5478 - val_loss: 1.8433 - val_categorical_accuracy: 0.5467\n",
      "Epoch 20/64\n",
      "894/894 [==============================] - 820s 917ms/step - loss: 1.6345 - categorical_accuracy: 0.5514 - val_loss: 1.8154 - val_categorical_accuracy: 0.5524\n",
      "Epoch 21/64\n",
      "894/894 [==============================] - 824s 922ms/step - loss: 1.6295 - categorical_accuracy: 0.5542 - val_loss: 1.6675 - val_categorical_accuracy: 0.5688\n",
      "Epoch 22/64\n",
      "894/894 [==============================] - 820s 918ms/step - loss: 1.6239 - categorical_accuracy: 0.5576 - val_loss: 1.7135 - val_categorical_accuracy: 0.5615\n",
      "Epoch 23/64\n",
      "894/894 [==============================] - 820s 917ms/step - loss: 1.6166 - categorical_accuracy: 0.5610 - val_loss: 1.7593 - val_categorical_accuracy: 0.5654\n",
      "Epoch 24/64\n",
      "894/894 [==============================] - 819s 917ms/step - loss: 1.6124 - categorical_accuracy: 0.5644 - val_loss: 1.8702 - val_categorical_accuracy: 0.5472\n",
      "Epoch 25/64\n",
      "894/894 [==============================] - 815s 912ms/step - loss: 1.6081 - categorical_accuracy: 0.5662 - val_loss: 1.9589 - val_categorical_accuracy: 0.5205\n",
      "Epoch 26/64\n",
      "894/894 [==============================] - 822s 919ms/step - loss: 1.6020 - categorical_accuracy: 0.5703 - val_loss: 1.6815 - val_categorical_accuracy: 0.5726\n",
      "Epoch 27/64\n",
      "894/894 [==============================] - 798s 892ms/step - loss: 1.5993 - categorical_accuracy: 0.5703 - val_loss: 2.0045 - val_categorical_accuracy: 0.5259\n",
      "Epoch 28/64\n",
      "894/894 [==============================] - 821s 918ms/step - loss: 1.5981 - categorical_accuracy: 0.5715 - val_loss: 1.7866 - val_categorical_accuracy: 0.5656\n",
      "Epoch 29/64\n",
      "894/894 [==============================] - 823s 920ms/step - loss: 1.5918 - categorical_accuracy: 0.5778 - val_loss: 1.8062 - val_categorical_accuracy: 0.5646\n",
      "Epoch 30/64\n",
      "894/894 [==============================] - 828s 926ms/step - loss: 1.5901 - categorical_accuracy: 0.5785 - val_loss: 1.7138 - val_categorical_accuracy: 0.5540\n",
      "Epoch 31/64\n",
      "894/894 [==============================] - 814s 911ms/step - loss: 1.5840 - categorical_accuracy: 0.5809 - val_loss: 1.9026 - val_categorical_accuracy: 0.5772\n",
      "Epoch 32/64\n",
      "894/894 [==============================] - 824s 922ms/step - loss: 1.5779 - categorical_accuracy: 0.5827 - val_loss: 1.5645 - val_categorical_accuracy: 0.5740\n",
      "Epoch 33/64\n",
      "894/894 [==============================] - 831s 929ms/step - loss: 1.5767 - categorical_accuracy: 0.5844 - val_loss: 1.6975 - val_categorical_accuracy: 0.5794\n",
      "Epoch 34/64\n",
      "894/894 [==============================] - 840s 940ms/step - loss: 1.5783 - categorical_accuracy: 0.5842 - val_loss: 1.6907 - val_categorical_accuracy: 0.5765\n",
      "Epoch 35/64\n",
      "894/894 [==============================] - 839s 939ms/step - loss: 1.5757 - categorical_accuracy: 0.5847 - val_loss: 1.4254 - val_categorical_accuracy: 0.5908\n",
      "Epoch 36/64\n",
      "894/894 [==============================] - 826s 924ms/step - loss: 1.5683 - categorical_accuracy: 0.5898 - val_loss: 1.7685 - val_categorical_accuracy: 0.5683\n",
      "Epoch 37/64\n",
      "894/894 [==============================] - 822s 920ms/step - loss: 1.5652 - categorical_accuracy: 0.5904 - val_loss: 1.6341 - val_categorical_accuracy: 0.5957\n",
      "Epoch 38/64\n",
      "894/894 [==============================] - 823s 921ms/step - loss: 1.5621 - categorical_accuracy: 0.5925 - val_loss: 1.7443 - val_categorical_accuracy: 0.5792\n",
      "Epoch 39/64\n",
      "894/894 [==============================] - 821s 919ms/step - loss: 1.5582 - categorical_accuracy: 0.5944 - val_loss: 1.6357 - val_categorical_accuracy: 0.5937\n",
      "Epoch 40/64\n",
      "894/894 [==============================] - 817s 914ms/step - loss: 1.5559 - categorical_accuracy: 0.5952 - val_loss: 1.7332 - val_categorical_accuracy: 0.5898\n",
      "Epoch 41/64\n",
      "894/894 [==============================] - 814s 910ms/step - loss: 1.5553 - categorical_accuracy: 0.5958 - val_loss: 1.7213 - val_categorical_accuracy: 0.5832\n",
      "Epoch 42/64\n",
      "894/894 [==============================] - 807s 903ms/step - loss: 1.5531 - categorical_accuracy: 0.5984 - val_loss: 1.6687 - val_categorical_accuracy: 0.5822\n",
      "Epoch 43/64\n",
      "894/894 [==============================] - 816s 913ms/step - loss: 1.5499 - categorical_accuracy: 0.5998 - val_loss: 1.7127 - val_categorical_accuracy: 0.5630\n",
      "Epoch 44/64\n",
      "894/894 [==============================] - 802s 897ms/step - loss: 1.5465 - categorical_accuracy: 0.6020 - val_loss: 1.7906 - val_categorical_accuracy: 0.5889\n",
      "Epoch 45/64\n",
      "894/894 [==============================] - 801s 896ms/step - loss: 1.5490 - categorical_accuracy: 0.6015 - val_loss: 1.7635 - val_categorical_accuracy: 0.5989\n",
      "Epoch 46/64\n",
      "894/894 [==============================] - 802s 897ms/step - loss: 1.5443 - categorical_accuracy: 0.6043 - val_loss: 1.6810 - val_categorical_accuracy: 0.5849\n",
      "Epoch 47/64\n",
      "894/894 [==============================] - 805s 900ms/step - loss: 1.5393 - categorical_accuracy: 0.6049 - val_loss: 1.9177 - val_categorical_accuracy: 0.5775\n",
      "Epoch 48/64\n",
      "894/894 [==============================] - 806s 901ms/step - loss: 1.5416 - categorical_accuracy: 0.6059 - val_loss: 1.5206 - val_categorical_accuracy: 0.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/64\n",
      "894/894 [==============================] - 796s 891ms/step - loss: 1.5408 - categorical_accuracy: 0.6063 - val_loss: 1.8897 - val_categorical_accuracy: 0.5987\n",
      "Epoch 50/64\n",
      "894/894 [==============================] - 799s 893ms/step - loss: 1.5359 - categorical_accuracy: 0.6084 - val_loss: 1.5234 - val_categorical_accuracy: 0.5964\n",
      "Epoch 51/64\n",
      "894/894 [==============================] - 796s 891ms/step - loss: 1.5348 - categorical_accuracy: 0.6098 - val_loss: 1.7408 - val_categorical_accuracy: 0.5846\n",
      "Epoch 52/64\n",
      "894/894 [==============================] - 803s 899ms/step - loss: 1.5357 - categorical_accuracy: 0.6095 - val_loss: 1.9562 - val_categorical_accuracy: 0.5761\n",
      "Epoch 53/64\n",
      "894/894 [==============================] - 804s 899ms/step - loss: 1.5310 - categorical_accuracy: 0.6111 - val_loss: 1.8733 - val_categorical_accuracy: 0.5941\n",
      "Epoch 54/64\n",
      "894/894 [==============================] - 725s 811ms/step - loss: 1.5287 - categorical_accuracy: 0.6130 - val_loss: 1.6795 - val_categorical_accuracy: 0.5870\n",
      "Epoch 55/64\n",
      "894/894 [==============================] - 677s 758ms/step - loss: 1.5291 - categorical_accuracy: 0.6124 - val_loss: 1.4659 - val_categorical_accuracy: 0.5922\n",
      "Epoch 56/64\n",
      "894/894 [==============================] - 671s 751ms/step - loss: 1.5251 - categorical_accuracy: 0.6148 - val_loss: 1.7401 - val_categorical_accuracy: 0.6033\n",
      "Epoch 57/64\n",
      "894/894 [==============================] - 679s 760ms/step - loss: 1.5225 - categorical_accuracy: 0.6161 - val_loss: 1.5990 - val_categorical_accuracy: 0.5921\n",
      "Epoch 58/64\n",
      "894/894 [==============================] - 677s 757ms/step - loss: 1.5248 - categorical_accuracy: 0.6145 - val_loss: 1.9104 - val_categorical_accuracy: 0.6119\n",
      "Epoch 59/64\n",
      "894/894 [==============================] - 668s 748ms/step - loss: 1.5175 - categorical_accuracy: 0.6188 - val_loss: 2.0562 - val_categorical_accuracy: 0.5802\n",
      "Epoch 60/64\n",
      "894/894 [==============================] - 698s 781ms/step - loss: 1.5198 - categorical_accuracy: 0.6167 - val_loss: 1.8668 - val_categorical_accuracy: 0.6140\n",
      "Epoch 61/64\n",
      "894/894 [==============================] - 680s 760ms/step - loss: 1.5167 - categorical_accuracy: 0.6188 - val_loss: 1.7206 - val_categorical_accuracy: 0.6113\n",
      "Epoch 62/64\n",
      "894/894 [==============================] - 678s 758ms/step - loss: 1.5136 - categorical_accuracy: 0.6208 - val_loss: 1.8191 - val_categorical_accuracy: 0.6111\n",
      "Epoch 63/64\n",
      "894/894 [==============================] - 677s 757ms/step - loss: 1.5088 - categorical_accuracy: 0.6221 - val_loss: 1.7878 - val_categorical_accuracy: 0.5968\n",
      "Epoch 64/64\n",
      "894/894 [==============================] - 677s 757ms/step - loss: 1.5100 - categorical_accuracy: 0.6229 - val_loss: 1.8576 - val_categorical_accuracy: 0.6006\n",
      "Evaluating generator with 6305 images\n",
      "Scores: [1.8575506210327148, 0.6006343960762024]\n",
      "\n",
      "Evaluating generator with 6328 images\n",
      "Scores: [1.9407844543457031, 0.5937104821205139]\n",
      "\n",
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.fit_from_generator(path=f'{dataset_path}/{dataset}', \n",
    "                         train_generator=train_generator, validation_generator=validation_generator,\n",
    "                         test_generator=test_generator,\n",
    "                         evaluate_net=False, use_model_check_point=True, use_early_stop=False, weighted=True,\n",
    "                         show_activations=False, n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification//models/PlacesOntop_Model/2020-01-05__18_54/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_model(model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_is_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notas:\n",
    "#### - Probar configuraciones 6, 7, 8 y 9.\n",
    "#### - Comparar mejor resultado con notebook placescnn_v2.1\n",
    "#### - Probar configuraciones desfrizando bloques convolutivos de la red"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
