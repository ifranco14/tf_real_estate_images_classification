{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.models import base_model, cnn_model\n",
    "from src import custom_losses, custom_metrics, optimizers\n",
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = data.PATH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'vision_based_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'{paths.PROCESSED_DATA_PATH}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = sorted([d for d in os.listdir(dataset_path) if dataset in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = directories[1:] + [directories[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vision_based_dataset_10',\n",
       " 'vision_based_dataset_20',\n",
       " 'vision_based_dataset_30',\n",
       " 'vision_based_dataset_40',\n",
       " 'vision_based_dataset_50',\n",
       " 'vision_based_dataset_60',\n",
       " 'vision_based_dataset_70',\n",
       " 'vision_based_dataset_80',\n",
       " 'vision_based_dataset_90',\n",
       " 'vision_based_dataset']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_classes = 6\n",
    "epochs = 100\n",
    "img_size = 128\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = f'{dataset_path}/{dataset}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\n",
    "    # 'vision_based_dataset_20',\n",
    "    # 'vision_based_dataset_30',\n",
    "    # 'vision_based_dataset_40',\n",
    "    #'vision_based_dataset_50',\n",
    "    # 'vision_based_dataset_60',\n",
    "    # 'vision_based_dataset_70',\n",
    "    # 'vision_based_dataset_80',\n",
    "    #'vision_based_dataset_90',\n",
    "    'vision_based_dataset'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: vision_based_dataset_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1124 19:35:44.059296 140636181731136 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44973 images belonging to 6 classes.\n",
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1124 19:35:46.086800 140636181731136 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "W1124 19:35:46.087576 140636181731136 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:356: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W1124 19:35:46.089438 140636181731136 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:357: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W1124 19:35:46.091266 140636181731136 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:358: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### CNN_Model #####\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 64)      4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 64)      102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 120, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 52, 52, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               44302848  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 45,029,446\n",
      "Trainable params: 45,028,678\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "\n",
      "class_weights [2.08904682 0.88047692 1.08677686 0.85682442 0.86954756 0.87086093]\n",
      "**** Class weights ****\n",
      "[2.08904682 0.88047692 1.08677686 0.85682442 0.86954756 0.87086093]\n",
      "*** ** *** *** *** ** ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1124 19:35:46.439905 140636181731136 deprecation.py:323] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1124 19:35:49.334578 140636181731136 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44973/44973 [==============================] - 17051s 379ms/step - loss: 9.0295 - categorical_accuracy: 0.3893 - val_loss: 1.2668 - val_categorical_accuracy: 0.5003\n",
      "Epoch 2/100\n",
      "44973/44973 [==============================] - 16640s 370ms/step - loss: 1.2339 - categorical_accuracy: 0.6529 - val_loss: 1.4766 - val_categorical_accuracy: 0.6688\n",
      "Epoch 3/100\n",
      "44973/44973 [==============================] - 16632s 370ms/step - loss: 1.0610 - categorical_accuracy: 0.7607 - val_loss: 1.2172 - val_categorical_accuracy: 0.6373\n",
      "Epoch 4/100\n",
      "44973/44973 [==============================] - 16284s 362ms/step - loss: 0.9539 - categorical_accuracy: 0.8112 - val_loss: 1.7406 - val_categorical_accuracy: 0.6284\n",
      "Epoch 5/100\n",
      "44973/44973 [==============================] - 16210s 360ms/step - loss: 0.8854 - categorical_accuracy: 0.8430 - val_loss: 0.6855 - val_categorical_accuracy: 0.6880\n",
      "Epoch 6/100\n",
      "44973/44973 [==============================] - 18373s 409ms/step - loss: 0.8358 - categorical_accuracy: 0.8636 - val_loss: 2.1959 - val_categorical_accuracy: 0.6544\n",
      "Epoch 7/100\n",
      "44973/44973 [==============================] - 17361s 386ms/step - loss: 0.7948 - categorical_accuracy: 0.8778 - val_loss: 1.0672 - val_categorical_accuracy: 0.6908\n",
      "Epoch 8/100\n",
      "44973/44973 [==============================] - 17321s 385ms/step - loss: 0.7580 - categorical_accuracy: 0.8887 - val_loss: 0.7084 - val_categorical_accuracy: 0.6808\n",
      "Epoch 9/100\n",
      "14677/44973 [========>.....................] - ETA: 2:43:59 - loss: 0.7370 - categorical_accuracy: 0.8948"
     ]
    }
   ],
   "source": [
    "for dataset in directories:\n",
    "    print(f'Starting experiment: {dataset}')\n",
    "    model = cnn_model.CNN_Model(batch_size, n_classes, epochs, img_size, n_channels, experiment_name=f'exp_2__{dataset}_')\n",
    "\n",
    "    train_generator = model.get_image_data_generator(f'{dataset_path}/{dataset}', train=True, validation=False)\n",
    "    validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=False, validation=True, test=True, class_mode_test='categorical')\n",
    "    \n",
    "    weights = model.get_class_weights(train_generator.classes, model)\n",
    "    model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "    #model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],)\n",
    "\n",
    "    model.show_summary()\n",
    "\n",
    "    steps_per_epoch, validation_steps = len(train_generator.classes), len(validation_generator.classes)\n",
    "\n",
    "    model.fit_from_generator(path=f'{dataset_path}/{dataset}',\n",
    "                             train_steps_per_epoch=steps_per_epoch, validation_steps_per_epoch=validation_steps, \n",
    "                             train_generator=train_generator, validation_generator=validation_generator,\n",
    "                             test_generator=test_generator,\n",
    "                             evaluate_net=False, use_model_check_point=True, use_early_stop=True, weighted=True,\n",
    "                             show_activations=False,)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: vision_based_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1128 00:45:04.698457 140684921956160 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114361 images belonging to 6 classes.\n",
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 00:45:08.159788 140684921956160 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "W1128 00:45:08.160526 140684921956160 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:356: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W1128 00:45:08.162595 140684921956160 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:357: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W1128 00:45:08.164842 140684921956160 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:358: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### CNN_Model #####\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 64)      4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 64)      102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 120, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 52, 52, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               44302848  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 45,029,446\n",
      "Trainable params: 45,028,678\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "\n",
      "class_weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "**** Class weights ****\n",
      "[2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "*** ** *** *** *** ** ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 00:45:08.444471 140684921956160 deprecation.py:323] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1128 00:45:10.979812 140684921956160 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "114361/114361 [==============================] - 37212s 325ms/step - loss: 5.7529 - categorical_accuracy: 0.5072 - val_loss: 1.0840 - val_categorical_accuracy: 0.7183\n",
      "Epoch 2/100\n",
      "114361/114361 [==============================] - 37346s 327ms/step - loss: 1.0949 - categorical_accuracy: 0.7400 - val_loss: 1.1225 - val_categorical_accuracy: 0.7419\n",
      "Epoch 3/100\n",
      " 23928/114361 [=====>........................] - ETA: 7:47:04 - loss: 1.0175 - categorical_accuracy: 0.7757"
     ]
    }
   ],
   "source": [
    "for dataset in directories:\n",
    "    print(f'Starting experiment: {dataset}')\n",
    "    model = cnn_model.CNN_Model(batch_size, n_classes, epochs, img_size, n_channels, experiment_name=f'exp_2__{dataset}_')\n",
    "\n",
    "    train_generator = model.get_image_data_generator(f'{dataset_path}/{dataset}', train=True, validation=False)\n",
    "    validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=False, validation=True, test=True, class_mode_test='categorical')\n",
    "    \n",
    "    weights = model.get_class_weights(train_generator.classes, model)\n",
    "    model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "    #model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],)\n",
    "\n",
    "    model.show_summary()\n",
    "\n",
    "    steps_per_epoch, validation_steps = len(train_generator.classes), len(validation_generator.classes)\n",
    "\n",
    "    model.fit_from_generator(path=f'{dataset_path}/{dataset}',\n",
    "                             train_steps_per_epoch=steps_per_epoch, validation_steps_per_epoch=validation_steps, \n",
    "                             train_generator=train_generator, validation_generator=validation_generator,\n",
    "                             test_generator=test_generator,\n",
    "                             evaluate_net=False, use_model_check_point=True, use_early_stop=True, weighted=True,\n",
    "                             show_activations=False,)\n",
    "    \n",
    "    #del model\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
