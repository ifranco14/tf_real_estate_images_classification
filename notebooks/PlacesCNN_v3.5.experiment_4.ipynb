{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import places_ontop_model\n",
    "from src import custom_losses, custom_metrics, optimizers\n",
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_classes = 6\n",
    "epochs = 40\n",
    "img_size = 224\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = places_ontop_model.PlacesOntop_Model(batch_size, n_classes, epochs, img_size, n_channels, version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = data.PATH()\n",
    "dataset_path = f'{paths.PROCESSED_DATA_PATH}/'\n",
    "dataset = 'vision_based_dataset'\n",
    "test_dataset_path = f'{dataset_path}/{dataset}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114361 images belonging to 6 classes.\n",
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=True, validation=True, test=True, class_mode_validation='categorical', class_mode_test='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_class_weights(train_generator.classes, model)\n",
    "model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# model.model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# instance_model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### PlacesOntop_Model #####\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 14,847,558\n",
      "Trainable params: 7,212,294\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.show_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0106 23:43:48.366911 140241531881280 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "**** Class weights ****\n",
      "[2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "*** ** *** *** *** ** ***\n",
      "Epoch 1/40\n",
      "894/894 [==============================] - 689s 771ms/step - loss: 1.5282 - categorical_accuracy: 0.3290 - val_loss: 1.3640 - val_categorical_accuracy: 0.4141\n",
      "Epoch 2/40\n",
      "894/894 [==============================] - 727s 813ms/step - loss: 1.3351 - categorical_accuracy: 0.4203 - val_loss: 1.3337 - val_categorical_accuracy: 0.4331\n",
      "Epoch 3/40\n",
      "894/894 [==============================] - 731s 818ms/step - loss: 1.2772 - categorical_accuracy: 0.4498 - val_loss: 1.0551 - val_categorical_accuracy: 0.4652\n",
      "Epoch 4/40\n",
      "894/894 [==============================] - 729s 816ms/step - loss: 1.2331 - categorical_accuracy: 0.4774 - val_loss: 1.2578 - val_categorical_accuracy: 0.4996\n",
      "Epoch 5/40\n",
      "894/894 [==============================] - 740s 828ms/step - loss: 1.1989 - categorical_accuracy: 0.4991 - val_loss: 1.4536 - val_categorical_accuracy: 0.5253\n",
      "Epoch 6/40\n",
      "894/894 [==============================] - 723s 809ms/step - loss: 1.1666 - categorical_accuracy: 0.5170 - val_loss: 1.2255 - val_categorical_accuracy: 0.5461\n",
      "Epoch 7/40\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 1.1349 - categorical_accuracy: 0.5353 - val_loss: 1.3138 - val_categorical_accuracy: 0.5377\n",
      "Epoch 8/40\n",
      "894/894 [==============================] - 727s 814ms/step - loss: 1.1039 - categorical_accuracy: 0.5521 - val_loss: 1.2085 - val_categorical_accuracy: 0.5599\n",
      "Epoch 9/40\n",
      "894/894 [==============================] - 725s 811ms/step - loss: 1.0803 - categorical_accuracy: 0.5641 - val_loss: 1.1998 - val_categorical_accuracy: 0.5697\n",
      "Epoch 10/40\n",
      "894/894 [==============================] - 735s 823ms/step - loss: 1.0541 - categorical_accuracy: 0.5778 - val_loss: 1.2535 - val_categorical_accuracy: 0.5748\n",
      "Epoch 11/40\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 1.0294 - categorical_accuracy: 0.5907 - val_loss: 1.2393 - val_categorical_accuracy: 0.5937\n",
      "Epoch 12/40\n",
      "894/894 [==============================] - 725s 811ms/step - loss: 1.0069 - categorical_accuracy: 0.5998 - val_loss: 1.3005 - val_categorical_accuracy: 0.5856\n",
      "Epoch 13/40\n",
      "894/894 [==============================] - 731s 818ms/step - loss: 0.9875 - categorical_accuracy: 0.6079 - val_loss: 1.0038 - val_categorical_accuracy: 0.6048\n",
      "Epoch 14/40\n",
      "894/894 [==============================] - 737s 824ms/step - loss: 0.9632 - categorical_accuracy: 0.6181 - val_loss: 0.9518 - val_categorical_accuracy: 0.6038\n",
      "Epoch 15/40\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 0.9449 - categorical_accuracy: 0.6261 - val_loss: 1.2131 - val_categorical_accuracy: 0.6211\n",
      "Epoch 16/40\n",
      "894/894 [==============================] - 728s 814ms/step - loss: 0.9220 - categorical_accuracy: 0.6341 - val_loss: 1.0739 - val_categorical_accuracy: 0.6225\n",
      "Epoch 17/40\n",
      "894/894 [==============================] - 728s 815ms/step - loss: 0.9030 - categorical_accuracy: 0.6433 - val_loss: 1.1655 - val_categorical_accuracy: 0.6092\n",
      "Epoch 18/40\n",
      "894/894 [==============================] - 725s 811ms/step - loss: 0.8861 - categorical_accuracy: 0.6497 - val_loss: 1.0821 - val_categorical_accuracy: 0.5965\n",
      "Epoch 19/40\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 0.8666 - categorical_accuracy: 0.6571 - val_loss: 1.0983 - val_categorical_accuracy: 0.6220\n",
      "Epoch 20/40\n",
      "894/894 [==============================] - 728s 814ms/step - loss: 0.8451 - categorical_accuracy: 0.6660 - val_loss: 1.2377 - val_categorical_accuracy: 0.6035\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "894/894 [==============================] - 729s 815ms/step - loss: 0.8301 - categorical_accuracy: 0.6692 - val_loss: 1.1642 - val_categorical_accuracy: 0.6285\n",
      "Epoch 22/40\n",
      "894/894 [==============================] - 728s 814ms/step - loss: 0.8125 - categorical_accuracy: 0.6773 - val_loss: 1.2832 - val_categorical_accuracy: 0.6092\n",
      "Epoch 23/40\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.7935 - categorical_accuracy: 0.6862Epoch 23/40\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 0.7934 - categorical_accuracy: 0.6863 - val_loss: 1.1975 - val_categorical_accuracy: 0.6197\n",
      "Epoch 24/40\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 0.7741 - categorical_accuracy: 0.6920 - val_loss: 1.3033 - val_categorical_accuracy: 0.6293\n",
      "Epoch 25/40\n",
      "894/894 [==============================] - 728s 814ms/step - loss: 0.7577 - categorical_accuracy: 0.6988 - val_loss: 1.1636 - val_categorical_accuracy: 0.6251\n",
      "Epoch 26/40\n",
      "894/894 [==============================] - 729s 816ms/step - loss: 0.7344 - categorical_accuracy: 0.7083 - val_loss: 1.3386 - val_categorical_accuracy: 0.6301\n",
      "Epoch 27/40\n",
      "894/894 [==============================] - 734s 821ms/step - loss: 0.7203 - categorical_accuracy: 0.7123 - val_loss: 1.2325 - val_categorical_accuracy: 0.6343\n",
      "Epoch 28/40\n",
      "894/894 [==============================] - 731s 818ms/step - loss: 0.7010 - categorical_accuracy: 0.7194 - val_loss: 1.4003 - val_categorical_accuracy: 0.6052\n",
      "Epoch 29/40\n",
      "894/894 [==============================] - 727s 813ms/step - loss: 0.6847 - categorical_accuracy: 0.7268 - val_loss: 1.1165 - val_categorical_accuracy: 0.6341\n",
      "Epoch 30/40\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 0.6636 - categorical_accuracy: 0.7345 - val_loss: 1.0530 - val_categorical_accuracy: 0.6330\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "894/894 [==============================] - 731s 818ms/step - loss: 0.6512 - categorical_accuracy: 0.7390 - val_loss: 1.6118 - val_categorical_accuracy: 0.6293\n",
      "Epoch 32/40\n",
      "894/894 [==============================] - 733s 819ms/step - loss: 0.6319 - categorical_accuracy: 0.7473 - val_loss: 1.2099 - val_categorical_accuracy: 0.6443\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "894/894 [==============================] - 733s 819ms/step - loss: 0.6319 - categorical_accuracy: 0.7473 - val_loss: 1.2099 - val_categorical_accuracy: 0.6443\n",
      "894/894 [==============================] - 734s 821ms/step - loss: 0.6159 - categorical_accuracy: 0.7535 - val_loss: 1.7445 - val_categorical_accuracy: 0.6293\n",
      "Epoch 34/40\n",
      "894/894 [==============================] - 733s 820ms/step - loss: 0.6008 - categorical_accuracy: 0.7584 - val_loss: 1.2327 - val_categorical_accuracy: 0.6428\n",
      "Epoch 35/40\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.5905 - categorical_accuracy: 0.7622 - val_loss: 1.3139 - val_categorical_accuracy: 0.6371\n",
      "Epoch 36/40\n",
      "894/894 [==============================] - 733s 819ms/step - loss: 0.5674 - categorical_accuracy: 0.7719 - val_loss: 1.2200 - val_categorical_accuracy: 0.6349\n",
      "Epoch 37/40\n",
      "894/894 [==============================] - 735s 823ms/step - loss: 0.5582 - categorical_accuracy: 0.7753 - val_loss: 1.7021 - val_categorical_accuracy: 0.6333\n",
      "Epoch 38/40\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.5439 - categorical_accuracy: 0.7807Epoch 38/40\n",
      "894/894 [==============================] - 732s 819ms/step - loss: 0.5440 - categorical_accuracy: 0.7806 - val_loss: 1.6741 - val_categorical_accuracy: 0.6358\n",
      "Epoch 39/40\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.5304 - categorical_accuracy: 0.7857 - val_loss: 1.5595 - val_categorical_accuracy: 0.6354\n",
      "Epoch 40/40\n",
      "894/894 [==============================] - 761s 851ms/step - loss: 0.5124 - categorical_accuracy: 0.7937 - val_loss: 1.4217 - val_categorical_accuracy: 0.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-342:\n",
      "Traceback (most recent call last):\n",
      "E0107 08:45:23.585539 140241531881280 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-24dbf5b95635>\", line 5, in <module>\n",
      "    show_activations=False, n_workers=4)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py\", line 388, in fit_from_generator\n",
      "    self.pred = self.predict_from_generator(path, test_generator, validation_generator)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py\", line 441, in predict_from_generator\n",
      "    workers=3,)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/engine/training.py\", line 1846, in predict_generator\n",
      "    verbose=verbose)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/engine/training_generator.py\", line 491, in predict_generator\n",
      "    generator_output = next(output_generator)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 610, in get\n",
      "    inputs = future.get(timeout=30)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 299, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit_from_generator(path=f'{dataset_path}/{dataset}', \n",
    "                         train_generator=train_generator, validation_generator=validation_generator,\n",
    "                         test_generator=test_generator,\n",
    "                         evaluate_net=False, use_model_check_point=True, use_early_stop=False, weighted=True,\n",
    "                         show_activations=False, n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification//models/PlacesOntop_Model/2020-01-05__18_54/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_model(model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_is_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notas:\n",
    "#### - Probar configuraciones 6, 7, 8 y 9.\n",
    "#### - Comparar mejor resultado con notebook placescnn_v2.1\n",
    "#### - Probar configuraciones desfrizando bloques convolutivos de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1215 16:28:29.501663 140671186286400 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "W1215 16:28:29.502433 140671186286400 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:352: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W1215 16:28:29.507600 140671186286400 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:353: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W1215 16:28:29.512035 140671186286400 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:354: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "**** Class weights ****\n",
      "[2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "*** ** *** *** *** ** ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1215 16:28:29.750370 140671186286400 deprecation.py:323] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1215 16:28:30.482717 140671186286400 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "894/894 [==============================] - 1038s 1s/step - loss: 2.4015 - categorical_accuracy: 0.2928 - val_loss: 2.1764 - val_categorical_accuracy: 0.3545\n",
      "Epoch 2/100\n",
      "894/894 [==============================] - 1060s 1s/step - loss: 2.2469 - categorical_accuracy: 0.3689 - val_loss: 2.0527 - val_categorical_accuracy: 0.4125\n",
      "Epoch 3/100\n",
      "894/894 [==============================] - 1051s 1s/step - loss: 2.1950 - categorical_accuracy: 0.3923 - val_loss: 2.1657 - val_categorical_accuracy: 0.4208\n",
      "Epoch 4/100\n",
      "894/894 [==============================] - 1051s 1s/step - loss: 2.1688 - categorical_accuracy: 0.4039 - val_loss: 2.0708 - val_categorical_accuracy: 0.4346\n",
      "Epoch 5/100\n",
      "894/894 [==============================] - 1047s 1s/step - loss: 2.1490 - categorical_accuracy: 0.4133 - val_loss: 2.0666 - val_categorical_accuracy: 0.4411\n",
      "Epoch 6/100\n",
      "894/894 [==============================] - 1049s 1s/step - loss: 2.1337 - categorical_accuracy: 0.4212 - val_loss: 2.1136 - val_categorical_accuracy: 0.4385\n",
      "Epoch 7/100\n",
      "894/894 [==============================] - 1046s 1s/step - loss: 2.1223 - categorical_accuracy: 0.4254 - val_loss: 2.0854 - val_categorical_accuracy: 0.4525\n",
      "Evaluating generator with 6305 images\n",
      "Scores: [2.085378885269165, 0.45249801874160767]\n",
      "\n",
      "Evaluating generator with 6328 images\n",
      "Scores: [2.1083033084869385, 0.4454804062843323]\n",
      "\n",
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.fit_from_generator(path=f'{dataset_path}/{dataset}', \n",
    "                         train_generator=train_generator, validation_generator=validation_generator,\n",
    "                         test_generator=test_generator,\n",
    "                         evaluate_net=False, use_model_check_point=True, use_early_stop=True, weighted=True,\n",
    "                         show_activations=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_is_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_from_generator() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a61bb5334137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_from_generator() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "model.predict_from_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
