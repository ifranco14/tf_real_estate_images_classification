{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.models import places_ontop_model, base_model\n",
    "from src import custom_losses, custom_metrics, optimizers\n",
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_classes = 6\n",
    "epochs = 50\n",
    "img_size = 224\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0108 19:44:59.675103 140446953277248 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = places_ontop_model.PlacesOntop_Model(batch_size, n_classes, epochs, img_size, n_channels, version=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = data.PATH()\n",
    "dataset_path = f'{paths.PROCESSED_DATA_PATH}/'\n",
    "dataset = 'vision_based_dataset'\n",
    "test_dataset_path = f'{dataset_path}/{dataset}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114361 images belonging to 6 classes.\n",
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=True, validation=True, test=True, class_mode_validation='categorical', class_mode_test='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_class_weights(train_generator.classes, model)\n",
    "model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# model.model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)\n",
    "# instance_model.compile(optimizer='adam', loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### PlacesOntop_Model #####\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 14,847,558\n",
      "Trainable params: 7,212,294\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.show_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0108 19:45:04.073527 140446953277248 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "W0108 19:45:04.074065 140446953277248 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:354: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0108 19:45:04.076248 140446953277248 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:355: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W0108 19:45:04.080461 140446953277248 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:356: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "**** Class weights ****\n",
      "[2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n",
      "*** ** *** *** *** ** ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0108 19:45:04.300964 140446953277248 deprecation.py:323] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0108 19:45:05.157852 140446953277248 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tesis_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "894/894 [==============================] - 679s 759ms/step - loss: 1.4400 - categorical_accuracy: 0.3728 - val_loss: 1.4598 - val_categorical_accuracy: 0.4249\n",
      "Epoch 2/50\n",
      "894/894 [==============================] - 759s 849ms/step - loss: 1.2904 - categorical_accuracy: 0.4482 - val_loss: 1.1976 - val_categorical_accuracy: 0.4755\n",
      "Epoch 3/50\n",
      "894/894 [==============================] - 745s 834ms/step - loss: 1.2215 - categorical_accuracy: 0.4852 - val_loss: 1.2324 - val_categorical_accuracy: 0.5045\n",
      "Epoch 4/50\n",
      "894/894 [==============================] - 746s 834ms/step - loss: 1.1648 - categorical_accuracy: 0.5193 - val_loss: 1.4653 - val_categorical_accuracy: 0.5356\n",
      "Epoch 5/50\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 1.1187 - categorical_accuracy: 0.5441 - val_loss: 1.3704 - val_categorical_accuracy: 0.5446\n",
      "Epoch 6/50\n",
      "894/894 [==============================] - 748s 837ms/step - loss: 1.0752 - categorical_accuracy: 0.5652 - val_loss: 1.2951 - val_categorical_accuracy: 0.5897\n",
      "Epoch 7/50\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 1.0418 - categorical_accuracy: 0.5838 - val_loss: 1.2821 - val_categorical_accuracy: 0.5867\n",
      "Epoch 8/50\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 1.0038 - categorical_accuracy: 0.6002 - val_loss: 1.3773 - val_categorical_accuracy: 0.5949\n",
      "Epoch 9/50\n",
      "894/894 [==============================] - 747s 836ms/step - loss: 0.9788 - categorical_accuracy: 0.6122 - val_loss: 1.1684 - val_categorical_accuracy: 0.6025\n",
      "Epoch 10/50\n",
      "894/894 [==============================] - 752s 841ms/step - loss: 0.9488 - categorical_accuracy: 0.6261 - val_loss: 1.1609 - val_categorical_accuracy: 0.6228\n",
      "Epoch 11/50\n",
      "894/894 [==============================] - 751s 840ms/step - loss: 0.9209 - categorical_accuracy: 0.6359 - val_loss: 1.0228 - val_categorical_accuracy: 0.6295\n",
      "Epoch 12/50\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 0.8963 - categorical_accuracy: 0.6485 - val_loss: 1.1193 - val_categorical_accuracy: 0.6084\n",
      "Epoch 13/50\n",
      "894/894 [==============================] - 747s 836ms/step - loss: 0.8667 - categorical_accuracy: 0.6597 - val_loss: 1.3125 - val_categorical_accuracy: 0.6324\n",
      "Epoch 14/50\n",
      "894/894 [==============================] - 748s 836ms/step - loss: 0.8430 - categorical_accuracy: 0.6677 - val_loss: 1.4985 - val_categorical_accuracy: 0.5857\n",
      "Epoch 15/50\n",
      "894/894 [==============================] - 753s 842ms/step - loss: 0.8235 - categorical_accuracy: 0.6770 - val_loss: 1.0387 - val_categorical_accuracy: 0.6506\n",
      "Epoch 16/50\n",
      "894/894 [==============================] - 751s 840ms/step - loss: 0.7919 - categorical_accuracy: 0.6893 - val_loss: 0.9958 - val_categorical_accuracy: 0.6436\n",
      "Epoch 17/50\n",
      "894/894 [==============================] - 746s 834ms/step - loss: 0.7664 - categorical_accuracy: 0.7001 - val_loss: 0.9286 - val_categorical_accuracy: 0.6565\n",
      "Epoch 18/50\n",
      "894/894 [==============================] - 749s 838ms/step - loss: 0.7433 - categorical_accuracy: 0.7077 - val_loss: 1.0450 - val_categorical_accuracy: 0.6430\n",
      "Epoch 19/50\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.7208 - categorical_accuracy: 0.7153Epoch 19/50\n",
      "894/894 [==============================] - 747s 835ms/step - loss: 0.7206 - categorical_accuracy: 0.7154 - val_loss: 0.8087 - val_categorical_accuracy: 0.6495\n",
      "Epoch 20/50\n",
      "894/894 [==============================] - 750s 838ms/step - loss: 0.6971 - categorical_accuracy: 0.7249 - val_loss: 0.8380 - val_categorical_accuracy: 0.6547\n",
      "Epoch 21/50\n",
      "894/894 [==============================] - 745s 833ms/step - loss: 0.6689 - categorical_accuracy: 0.7350 - val_loss: 1.3560 - val_categorical_accuracy: 0.6466\n",
      "Epoch 22/50\n",
      "894/894 [==============================] - 757s 847ms/step - loss: 0.6488 - categorical_accuracy: 0.7420 - val_loss: 1.0061 - val_categorical_accuracy: 0.6462\n",
      "Epoch 23/50\n",
      "894/894 [==============================] - 758s 848ms/step - loss: 0.6198 - categorical_accuracy: 0.7533 - val_loss: 0.8547 - val_categorical_accuracy: 0.6476\n",
      "Epoch 24/50\n",
      "894/894 [==============================] - 750s 839ms/step - loss: 0.5982 - categorical_accuracy: 0.7610 - val_loss: 0.9660 - val_categorical_accuracy: 0.6568\n",
      "Epoch 25/50\n",
      "894/894 [==============================] - 744s 833ms/step - loss: 0.5729 - categorical_accuracy: 0.7706 - val_loss: 1.3644 - val_categorical_accuracy: 0.6385\n",
      "Epoch 26/50\n",
      "894/894 [==============================] - 741s 829ms/step - loss: 0.5504 - categorical_accuracy: 0.7802 - val_loss: 1.0810 - val_categorical_accuracy: 0.6531\n",
      "Epoch 27/50\n",
      "894/894 [==============================] - 737s 824ms/step - loss: 0.5300 - categorical_accuracy: 0.7866 - val_loss: 1.0500 - val_categorical_accuracy: 0.6465\n",
      "Epoch 28/50\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.5111 - categorical_accuracy: 0.7946 - val_loss: 0.9054 - val_categorical_accuracy: 0.6531\n",
      "Epoch 29/50\n",
      "894/894 [==============================] - 743s 831ms/step - loss: 0.4915 - categorical_accuracy: 0.8030 - val_loss: 1.0311 - val_categorical_accuracy: 0.6435\n",
      "Epoch 30/50\n",
      "894/894 [==============================] - 736s 824ms/step - loss: 0.4706 - categorical_accuracy: 0.8099 - val_loss: 1.1357 - val_categorical_accuracy: 0.6519\n",
      "Epoch 31/50\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.4466 - categorical_accuracy: 0.8206 - val_loss: 1.4779 - val_categorical_accuracy: 0.6512\n",
      "Epoch 32/50\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.4272 - categorical_accuracy: 0.8280 - val_loss: 0.9167 - val_categorical_accuracy: 0.6487\n",
      "Epoch 33/50\n",
      "894/894 [==============================] - 731s 818ms/step - loss: 0.4133 - categorical_accuracy: 0.8336 - val_loss: 1.1716 - val_categorical_accuracy: 0.6487\n",
      "Epoch 34/50\n",
      "894/894 [==============================] - 737s 825ms/step - loss: 0.4029 - categorical_accuracy: 0.8366 - val_loss: 1.0837 - val_categorical_accuracy: 0.6533\n",
      "Epoch 35/50\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.3785 - categorical_accuracy: 0.8476Epoch 35/50\n",
      "894/894 [==============================] - 740s 827ms/step - loss: 0.3784 - categorical_accuracy: 0.8477 - val_loss: 1.6185 - val_categorical_accuracy: 0.6561\n",
      "Epoch 36/50\n",
      "894/894 [==============================] - 734s 821ms/step - loss: 0.3670 - categorical_accuracy: 0.8522 - val_loss: 0.7821 - val_categorical_accuracy: 0.6533\n",
      "Epoch 37/50\n",
      "894/894 [==============================] - 738s 825ms/step - loss: 0.3513 - categorical_accuracy: 0.8578 - val_loss: 1.3226 - val_categorical_accuracy: 0.6420\n",
      "Epoch 38/50\n",
      "894/894 [==============================] - 736s 823ms/step - loss: 0.3344 - categorical_accuracy: 0.8642 - val_loss: 1.4615 - val_categorical_accuracy: 0.6557\n",
      "Epoch 39/50\n",
      "894/894 [==============================] - 736s 824ms/step - loss: 0.3300 - categorical_accuracy: 0.8662 - val_loss: 1.0916 - val_categorical_accuracy: 0.6384\n",
      "Epoch 40/50\n",
      "894/894 [==============================] - 732s 819ms/step - loss: 0.3131 - categorical_accuracy: 0.8735 - val_loss: 1.3988 - val_categorical_accuracy: 0.6509\n",
      "Epoch 41/50\n",
      "894/894 [==============================] - 723s 809ms/step - loss: 0.3065 - categorical_accuracy: 0.8759 - val_loss: 1.8348 - val_categorical_accuracy: 0.6577\n",
      "Epoch 42/50\n",
      "894/894 [==============================] - 728s 815ms/step - loss: 0.2871 - categorical_accuracy: 0.8839 - val_loss: 1.5488 - val_categorical_accuracy: 0.6406\n",
      "Epoch 43/50\n",
      "894/894 [==============================] - 726s 812ms/step - loss: 0.2778 - categorical_accuracy: 0.8868 - val_loss: 1.0249 - val_categorical_accuracy: 0.6503\n",
      "Epoch 44/50\n",
      "894/894 [==============================] - 727s 813ms/step - loss: 0.2693 - categorical_accuracy: 0.8908 - val_loss: 1.3997 - val_categorical_accuracy: 0.6443\n",
      "Epoch 45/50\n",
      "894/894 [==============================] - 727s 813ms/step - loss: 0.2693 - categorical_accuracy: 0.8908 - val_loss: 1.3997 - val_categorical_accuracy: 0.6443\n",
      "894/894 [==============================] - 725s 811ms/step - loss: 0.2647 - categorical_accuracy: 0.8931 - val_loss: 1.3012 - val_categorical_accuracy: 0.6474\n",
      "Epoch 46/50\n",
      "894/894 [==============================] - 727s 813ms/step - loss: 0.2513 - categorical_accuracy: 0.8988 - val_loss: 2.2018 - val_categorical_accuracy: 0.6454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "894/894 [==============================] - 715s 800ms/step - loss: 0.2441 - categorical_accuracy: 0.9015 - val_loss: 1.6863 - val_categorical_accuracy: 0.6433\n",
      "Epoch 48/50\n",
      "894/894 [==============================] - 718s 803ms/step - loss: 0.2314 - categorical_accuracy: 0.9074 - val_loss: 2.0743 - val_categorical_accuracy: 0.6439\n",
      "Epoch 49/50\n",
      "893/894 [============================>.] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9068Epoch 49/50\n",
      "894/894 [==============================] - 722s 807ms/step - loss: 0.2323 - categorical_accuracy: 0.9068 - val_loss: 1.2785 - val_categorical_accuracy: 0.6474\n",
      "Epoch 50/50\n",
      "894/894 [==============================] - 722s 808ms/step - loss: 0.2178 - categorical_accuracy: 0.9129 - val_loss: 2.0544 - val_categorical_accuracy: 0.6558\n",
      "Evaluating generator with 6305 images\n",
      "Scores: [2.0544164180755615, 0.6558287143707275]\n",
      "\n",
      "Evaluating generator with 6328 images\n",
      "Scores: [2.594451904296875, 0.6498103737831116]\n",
      "\n",
      "weights [2.09728947 0.87794411 1.08704042 0.8524606  0.87239869 0.87343812]\n"
     ]
    }
   ],
   "source": [
    "model.fit_from_generator(path=f'{dataset_path}/{dataset}', \n",
    "                         train_generator=train_generator, validation_generator=validation_generator,\n",
    "                         test_generator=test_generator,\n",
    "                         evaluate_net=False, use_model_check_point=True, use_early_stop=False, weighted=True,\n",
    "                         show_activations=False, n_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification//models/PlacesOntop_Model/2020-01-05__18_54/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification//models/PlacesOntop_Model/2020-01-08__19_44__exp_4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0117 16:45:26.194555 140195973494592 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:111: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0117 16:45:26.199860 140195973494592 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:112: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W0117 16:45:26.202467 140195973494592 deprecation_wrapper.py:119] From /home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification/src/models/base_model.py:113: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = base_model.BaseModel.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6305 images belonging to 6 classes.\n",
      "Found 6328 images belonging to 6 classes.\n",
      "Found 114361 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "paths = data.PATH()\n",
    "\n",
    "dataset = 'vision_based_dataset'\n",
    "\n",
    "dataset_path = f'{paths.PROCESSED_DATA_PATH}/'\n",
    "test_dataset_path = f'{dataset_path}/{dataset}/'\n",
    "\n",
    "validation_generator, test_generator = model.get_image_data_generator(test_dataset_path, train=False, validation=True, test=True, class_mode_validation='categorical', class_mode_test='categorical')\n",
    "\n",
    "train_generator = model.get_image_data_generator(f'{test_dataset_path}', train=True, validation=False)\n",
    "weights = model.get_class_weights(train_generator.classes, model)\n",
    "model.model.load_weights('/home/ifranco/Documents/facultad/tesis/tf_real_estate_images_classification//models/PlacesOntop_Model/2020-01-08__19_44__exp_4/weights.41-1.83.hdf5')\n",
    "model.compile(loss=custom_losses.weighted_categorical_crossentropy(weights), metrics=['categorical_accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating generator with 6305 images\n",
      "Scores: [1.5953874063491822, 0.65773195]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.scores = model.evaluate_from_generator(f'{dataset_path}/{dataset}', test_generator=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating generator with 6328 images\n",
      "Scores: [1.6277642011642457, 0.6396966]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.scores_test = model.evaluate_from_generator(f'{dataset_path}/{dataset}', test_generator=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
